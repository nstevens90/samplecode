{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0: pull packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model, model_selection, ensemble, svm, naive_bayes, preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import getpass\n",
    "import pyodbc\n",
    "import sys\n",
    "import sqlalchemy\n",
    "import urllib\n",
    "from datetime import date\n",
    "from collections import Counter\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import seaborn as sns\n",
    "import time\n",
    "from catboost import Pool, CatBoostClassifier, CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 0.1: pull data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql = pd.DataFrame() \n",
    "df_sql['servers'] = [serverlist]\n",
    "df_sql['databases'] = [databaselist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in zip(df_sql.servers, df_sql.databases): \n",
    "    if a == df_sql['servers'][0] and b == df_sql['databases'][0]:\n",
    "        params = urllib.parse.quote_plus(\"DSN={};DATABASE={};Trusted_Connection=yes\".format(a,b))\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    " \n",
    "        result = engine.execute('SELECT DISTINCT * FROM Y_DS_NewMember_001_ACA_Info')\n",
    "        df_mem = pd.DataFrame(result.fetchall(),columns=result.keys())\n",
    "\n",
    "    else:\n",
    "        params = urllib.parse.quote_plus(\"DSN={};DATABASE={};Trusted_Connection=yes\".format(a,b))\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "\n",
    "        result = engine.execute('SELECT DISTINCT * FROM Y_DS_NewMember_001_ACA_Info')\n",
    "        df_mem = df_mem.append(pd.DataFrame(result.fetchall(),columns=result.keys()))\n",
    "        df_mem['clientDB'] = df_mem['clientDB'].fillna(b)\n",
    "        \n",
    "    if a == df_sql['servers'][0] and b == df_sql['databases'][0]:\n",
    "        params = urllib.parse.quote_plus(\"DSN={};DATABASE={};Trusted_Connection=yes\".format(a,b))\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    " \n",
    "        result = engine.execute('SELECT DISTINCT * FROM Y_DS_NewMember_002_capturedconditions')\n",
    "        df_cc = pd.DataFrame(result.fetchall(),columns=result.keys())\n",
    "        df_cc['clientDB'] = b\n",
    "\n",
    "    else:\n",
    "        params = urllib.parse.quote_plus(\"DSN={};DATABASE={};Trusted_Connection=yes\".format(a,b))\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "\n",
    "        result = engine.execute('SELECT DISTINCT * FROM Y_DS_NewMember_002_capturedconditions')\n",
    "        df_cc = df_cc.append(pd.DataFrame(result.fetchall(),columns=result.keys()))\n",
    "        df_cc['clientDB'] = df_cc['clientDB'].fillna(b)\n",
    "        \n",
    "    if a == df_sql['servers'][0] and b == df_sql['databases'][0]:\n",
    "        params = urllib.parse.quote_plus(\"DSN={};DATABASE={};Trusted_Connection=yes\".format(a,b))\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    " \n",
    "        result = engine.execute('SELECT DISTINCT * FROM Y_DS_NewMember_003_nonscoredconditions')\n",
    "        df_noncc = pd.DataFrame(result.fetchall(),columns=result.keys())\n",
    "        df_noncc['clientDB'] = b\n",
    "\n",
    "    else:\n",
    "        params = urllib.parse.quote_plus(\"DSN={};DATABASE={};Trusted_Connection=yes\".format(a,b))\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "\n",
    "        result = engine.execute('SELECT DISTINCT * FROM Y_DS_NewMember_003_nonscoredconditions')\n",
    "        df_noncc = df_noncc.append(pd.DataFrame(result.fetchall(),columns=result.keys()))\n",
    "        df_noncc['clientDB'] = df_noncc['clientDB'].fillna(b)\n",
    "        \n",
    "    if a == df_sql['servers'][0] and b == df_sql['databases'][0]:\n",
    "        params = urllib.parse.quote_plus(\"DSN={};DATABASE={};Trusted_Connection=yes\".format(a,b))\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    " \n",
    "        result = engine.execute('SELECT DISTINCT * FROM Y_DS_NewMember_004_procedures')\n",
    "        df_procs = pd.DataFrame(result.fetchall(),columns=result.keys())\n",
    "        df_procs['clientDB'] = b\n",
    "\n",
    "    else:\n",
    "        params = urllib.parse.quote_plus(\"DSN={};DATABASE={};Trusted_Connection=yes\".format(a,b))\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "\n",
    "        result = engine.execute('SELECT DISTINCT * FROM Y_DS_NewMember_004_procedures')\n",
    "        df_procs = df_procs.append(pd.DataFrame(result.fetchall(),columns=result.keys()))\n",
    "        df_procs['clientDB'] = df_procs['clientDB'].fillna(b)\n",
    "        \n",
    "    if a == df_sql['servers'][0] and b == df_sql['databases'][0]:\n",
    "        params = urllib.parse.quote_plus(\"DSN={};DATABASE={};Trusted_Connection=yes\".format(a,b))\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    " \n",
    "        result = engine.execute('SELECT DISTINCT * FROM Y_DS_NewMember_005_drugs')\n",
    "        df_drugs = pd.DataFrame(result.fetchall(),columns=result.keys())\n",
    "        df_drugs['clientDB'] = b\n",
    "\n",
    "    else:\n",
    "        params = urllib.parse.quote_plus(\"DSN={};DATABASE={};Trusted_Connection=yes\".format(a,b))\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "\n",
    "        result = engine.execute('SELECT DISTINCT * FROM Y_DS_NewMember_005_drugs')\n",
    "        df_drugs = df_drugs.append(pd.DataFrame(result.fetchall(),columns=result.keys()))\n",
    "        df_drugs['clientDB'] = df_drugs['clientDB'].fillna(b)\n",
    "        \n",
    "    if a == df_sql['servers'][0] and b == df_sql['databases'][0]:\n",
    "        params = urllib.parse.quote_plus(\"DSN={};DATABASE={};Trusted_Connection=yes\".format(a,b))\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    " \n",
    "        result = engine.execute('SELECT DISTINCT * FROM Y_DS_NewMember_006_county_tpd')\n",
    "        df_tpd = pd.DataFrame(result.fetchall(),columns=result.keys())\n",
    "\n",
    "    else:\n",
    "        params = urllib.parse.quote_plus(\"DSN={};DATABASE={};Trusted_Connection=yes\".format(a,b))\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "\n",
    "        result = engine.execute('SELECT DISTINCT * FROM Y_DS_NewMember_006_county_tpd')\n",
    "        df_tpd = df_tpd.append(pd.DataFrame(result.fetchall(),columns=result.keys()))\n",
    "        df_tpd['clientDB'] = df_tpd['clientDB'].fillna(b)\n",
    "        \n",
    "    if a == df_sql['servers'][0] and b == df_sql['databases'][0]:\n",
    "        params = urllib.parse.quote_plus(\"DSN={};DATABASE={};Trusted_Connection=yes\".format(a,b))\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    " \n",
    "        result = engine.execute('SELECT DISTINCT * FROM Y_DS_NewMember_008_targets')\n",
    "        df_targets = pd.DataFrame(result.fetchall(),columns=result.keys())\n",
    "\n",
    "    else:\n",
    "        params = urllib.parse.quote_plus(\"DSN={};DATABASE={};Trusted_Connection=yes\".format(a,b))\n",
    "        engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "\n",
    "        result = engine.execute('SELECT DISTINCT * FROM Y_DS_NewMember_008_targets')\n",
    "        df_targets = df_targets.append(pd.DataFrame(result.fetchall(),columns=result.keys()))\n",
    "        df_targets['clientDB'] = df_targets['clientDB'].fillna(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2: prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc_pivot = pd.pivot_table(df_cc, values='instances', index=['clientDSMemberKey','clientDB','active_year'], columns=['CC']).add_suffix('_captured')\n",
    "df_noncc_pivot = pd.pivot_table(df_noncc, values='instances', index=['clientDSMemberKey','clientDB','active_year'], columns=['CC']).add_suffix('_noncaptured')\n",
    "df_drugs['drug_subclass'] = pd.to_numeric(df_drugs.drug_subclass)\n",
    "df_drugs100 = df_drugs[['drug_subclass','instances']].groupby('drug_subclass').sum().sort_values('instances',ascending=False)[0:100].reset_index()\n",
    "df_drugs=df_drugs.merge(df_drugs100, how='inner', on='drug_subclass').drop('instances_y',axis=1)\n",
    "df_drugs_pivot = pd.pivot_table(df_drugs, values='instances_x', index=['clientDSMemberKey','clientDB','active_year'],columns=['drug_subclass'])\n",
    "df_drugs_pivot.columns = df_drugs_pivot.columns.astype(str)\n",
    "df_procs['description'] = df_procs['category'] + \"_\" + df_procs['class']\n",
    "df_procs_pivot = pd.pivot_table(df_procs, values='instances', index=['clientDSMemberKey','clientDB','active_year'],columns=['description'])\n",
    "df_tpd_pivot = pd.pivot_table(df_tpd, values='value', index=['clientDSMemberKey','clientDB'],columns=['metric'])\n",
    "df_noncc_pivot = df_noncc_pivot.reset_index()\n",
    "df_cc_pivot = df_cc_pivot.reset_index()\n",
    "df_drugs_pivot = df_drugs_pivot.reset_index()\n",
    "df_procs_pivot = df_procs_pivot.reset_index()\n",
    "df_tpd_pivot = df_tpd_pivot.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_mem, df_noncc_pivot, on=['clientDSMemberKey','clientDB','active_year'],how='left')\n",
    "df_final = pd.merge(df_final, df_cc_pivot, on=['clientDSMemberKey','clientDB','active_year'],how='left')\n",
    "df_final = pd.merge(df_final, df_drugs_pivot, on=['clientDSMemberKey','clientDB','active_year'],how='left')\n",
    "df_final = pd.merge(df_final, df_procs_pivot, on=['clientDSMemberKey','clientDB','active_year'],how='left')\n",
    "df_final = pd.merge(df_final, df_tpd_pivot, on=['clientDSMemberKey','clientDB'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['sex'] = df_final['sex'].map({'M':1, 'F':0})\n",
    "df_final['relationship']=df_final['relationship'].map({' ':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_noncc_pivot\n",
    "del df_cc_pivot\n",
    "del df_drugs_pivot\n",
    "del df_procs_pivot\n",
    "del df_tpd_pivot\n",
    "del df_noncc\n",
    "del df_cc\n",
    "del df_drugs\n",
    "del df_procs\n",
    "del df_tpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_final, df_targets, on=['clientDSMemberKey','clientDB','active_year'],how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3: prepare targets and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['sumCost'] = df_final['medClaimTotal_y']+df_final['rxClaimTotal_y']\n",
    "df_final['drops'] = ((df_final['Coverage_Months_Actual'] <= 2) & (df_final['Coverage_Months_Actual'] > 1))*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['medClaimTotal_x']=df_final['medClaimTotal_x'].astype('float')\n",
    "df_final['rxClaimTotal_x']=df_final['rxClaimTotal_x'].astype('float')\n",
    "df_final['sumCost']=df_final['sumCost'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['metalLevel']=df_final['metalLevel'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [featurelist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0: cost model - catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.loc[df_final['sumCost']/12 < 100, 'costCatActual'] = 'low'\n",
    "df_final.loc[df_final['sumCost']/12 >= 2500, 'costCatActual'] = 'high'\n",
    "df_final.fillna({'costCatActual':'med'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low     1125918\n",
       "med      481335\n",
       "high      67031\n",
       "Name: costCatActual, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['costCatActual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(df_final[features], df_final['costCatActual'], test_size=0.1,random_state=5)\n",
    "categorical_features_indices = np.where(df_final[features].dtypes != np.float)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit_classification(alg, X_train, y_train, X_test, y_test, categorical_features_indices, useTrainCV=True, cv_folds=3, early_stopping_rounds=50):\n",
    "    \n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X_train, y_train, categorical_features_indices)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_train)\n",
    "    dtrain_predprob = alg.predict_proba(X_train)[:,1]\n",
    "    \n",
    "    #Predict test set:\n",
    "    dtest_predictions = alg.predict(X_test)\n",
    "    dtest_predprob = alg.predict_proba(X_test)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % accuracy_score(y_train, dtrain_predictions))\n",
    "    print(classification_report(y_train, dtrain_predictions))\n",
    "    print(confusion_matrix(y_train, dtrain_predictions, labels = ['low', 'med', 'high']))\n",
    "    cnf_matrix = confusion_matrix(y_train, dtrain_predictions, labels = ['low', 'med', 'high'])\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['low', 'med', 'high'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % accuracy_score(y_test.values, dtest_predictions))\n",
    "    print(classification_report(y_test, dtest_predictions))\n",
    "    print(confusion_matrix(y_test, dtest_predictions, labels = ['low', 'med', 'high']))\n",
    "    cnf_matrix = confusion_matrix(y_test, dtest_predictions, labels = ['low', 'med', 'high'])\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['low', 'med', 'high'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "                    \n",
    "    feat_imp = pd.DataFrame({'features':features})\n",
    "    feat_imp['importance'] = alg.feature_importances_\n",
    "    feat_imp = feat_imp.sort_values(by = 'importance', ascending=False).head(20)\n",
    "    feat_imp.plot(x='features', y='importance', kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_class14 = CatBoostClassifier(\n",
    "    iterations=250,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='MultiClassOneVsAll',\n",
    "    eval_metric='Accuracy',\n",
    "    leaf_estimation_method='Newton',\n",
    "    thread_count = 4,\n",
    "    l2_leaf_reg=1,\n",
    "    random_state=27,\n",
    "    class_weights = [1, 1, 1],\n",
    "    ## high, low, med\n",
    "    metric_period=10\n",
    ")\n",
    "modelfit_classification(catboost_class14, X_train, y_train, X_test, y_test, categorical_features_indices, useTrainCV=True, cv_folds=3, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_class15 = CatBoostClassifier(\n",
    "    iterations=250,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='MultiClassOneVsAll',\n",
    "    eval_metric='Accuracy',\n",
    "    leaf_estimation_method='Newton',\n",
    "    thread_count = 4,\n",
    "    l2_leaf_reg=1,\n",
    "    random_state=27,\n",
    "    class_weights = [2, 1, 1],\n",
    "    ## high, low, med\n",
    "    metric_period=10\n",
    ")\n",
    "modelfit_classification(catboost_class15, X_train, y_train, X_test, y_test, categorical_features_indices, useTrainCV=True, cv_folds=3, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_class18 = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.2,\n",
    "    depth=6,\n",
    "    loss_function='MultiClassOneVsAll',\n",
    "    eval_metric='Accuracy',\n",
    "    leaf_estimation_method='Newton',\n",
    "    thread_count = 4,\n",
    "    l2_leaf_reg=1,\n",
    "    random_state=27,\n",
    "    class_weights = [2.5, 1, 1],\n",
    "    ## high, low, med\n",
    "    metric_period=10\n",
    ")\n",
    "modelfit_classification(catboost_class18, X_train, y_train, X_test, y_test, categorical_features_indices, useTrainCV=True, cv_folds=3, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1: very high cost testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##very high testing\n",
    "df_final.loc[df_final['sumCost']/12 < 100, 'costCatActual'] = 'low'\n",
    "df_final.loc[(df_final['sumCost']/12 >= 2500) & (df_final['sumCost']/12 < 12000), 'costCatActual'] = 'high'\n",
    "df_final.loc[df_final['sumCost']/12 >= 12000, 'costCatActual'] = 'very high'\n",
    "df_final.fillna({'costCatActual':'med'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low          1125918\n",
       "med           481335\n",
       "high           53011\n",
       "very high      14020\n",
       "Name: costCatActual, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['costCatActual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(df_final[features], df_final['costCatActual'], test_size=0.1,random_state=5)\n",
    "categorical_features_indices = np.where(df_final[features].dtypes != np.float)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit_classification(alg, X_train, y_train, X_test, y_test, categorical_features_indices, useTrainCV=True, cv_folds=3, early_stopping_rounds=50):\n",
    "    \n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X_train, y_train, categorical_features_indices)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_train)\n",
    "    dtrain_predprob = alg.predict_proba(X_train)[:,1]\n",
    "    \n",
    "    #Predict test set:\n",
    "    dtest_predictions = alg.predict(X_test)\n",
    "    dtest_predprob = alg.predict_proba(X_test)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % accuracy_score(y_train, dtrain_predictions))\n",
    "    print(classification_report(y_train, dtrain_predictions))\n",
    "    print(confusion_matrix(y_train, dtrain_predictions, labels = ['low', 'med', 'high']))\n",
    "    cnf_matrix = confusion_matrix(y_train, dtrain_predictions, labels = ['low', 'med', 'high'])\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['low', 'med', 'high'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % accuracy_score(y_test.values, dtest_predictions))\n",
    "    print(classification_report(y_test, dtest_predictions))\n",
    "    print(confusion_matrix(y_test, dtest_predictions, labels = ['low', 'med', 'high']))\n",
    "    cnf_matrix = confusion_matrix(y_test, dtest_predictions, labels = ['low', 'med', 'high'])\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['low', 'med', 'high'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "                    \n",
    "    feat_imp = pd.DataFrame({'features':features})\n",
    "    feat_imp['importance'] = alg.feature_importances_\n",
    "    feat_imp = feat_imp.sort_values(by = 'importance', ascending=False).head(20)\n",
    "    feat_imp.plot(x='features', y='importance', kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_class1 = CatBoostClassifier(\n",
    "    iterations=250,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='MultiClassOneVsAll',\n",
    "    eval_metric='Accuracy',\n",
    "    leaf_estimation_method='Newton',\n",
    "    thread_count = 4,\n",
    "    l2_leaf_reg=1,\n",
    "    random_state=27,\n",
    "    class_weights = [1, 1, 1, 1],\n",
    "    ##low, med, high, veryhigh\n",
    "    metric_period=10\n",
    ")\n",
    "modelfit_classification(catboost_class1, X_train, y_train, X_test, y_test, categorical_features_indices, useTrainCV=True, cv_folds=3, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_class4 = CatBoostClassifier(\n",
    "    iterations=250,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='MultiClassOneVsAll',\n",
    "    eval_metric='Accuracy',\n",
    "    leaf_estimation_method='Newton',\n",
    "    thread_count = 4,\n",
    "    l2_leaf_reg=1,\n",
    "    random_state=27,\n",
    "    class_weights = [1, 1, 2, 5],\n",
    "    ##low, med, high, veryhigh\n",
    "    metric_period=10\n",
    ")\n",
    "modelfit_classification(catboost_class4, X_train, y_train, X_test, y_test, categorical_features_indices, useTrainCV=True, cv_folds=3, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0: risk model - catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.loc[df_final['TotalRiskTarget'] < 1, 'riskCatActual'] = 'low'\n",
    "df_final.loc[df_final['TotalRiskTarget'] >= 3, 'riskCatActual'] = 'high'\n",
    "df_final.fillna({'riskCatActual':'med'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low     1238194\n",
       "med      213494\n",
       "high     197843\n",
       "Name: riskCatActual, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['riskCatActual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(df_final[features], df_final['riskCatActual'], test_size=0.1,random_state=5)\n",
    "categorical_features_indices = np.where(df_final[features].dtypes != np.float)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit_classification(alg, X_train, y_train, X_test, y_test, categorical_features_indices, useTrainCV=True, cv_folds=3, early_stopping_rounds=50):\n",
    "    \n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X_train, y_train, categorical_features_indices)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_train)\n",
    "    dtrain_predprob = alg.predict_proba(X_train)[:,1]\n",
    "    \n",
    "    #Predict test set:\n",
    "    dtest_predictions = alg.predict(X_test)\n",
    "    dtest_predprob = alg.predict_proba(X_test)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % accuracy_score(y_train, dtrain_predictions))\n",
    "    print(classification_report(y_train, dtrain_predictions))\n",
    "    print(confusion_matrix(y_train, dtrain_predictions, labels = ['low', 'med', 'high']))\n",
    "    cnf_matrix = confusion_matrix(y_train, dtrain_predictions, labels = ['low', 'med', 'high'])\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['low', 'med', 'high'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % accuracy_score(y_test.values, dtest_predictions))\n",
    "    print(classification_report(y_test, dtest_predictions))\n",
    "    print(confusion_matrix(y_test, dtest_predictions, labels = ['low', 'med', 'high']))\n",
    "    cnf_matrix = confusion_matrix(y_test, dtest_predictions, labels = ['low', 'med', 'high'])\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['low', 'med', 'high'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "                    \n",
    "    feat_imp = pd.DataFrame({'features':features})\n",
    "    feat_imp['importance'] = alg.feature_importances_\n",
    "    feat_imp = feat_imp.sort_values(by = 'importance', ascending=False).head(20)\n",
    "    feat_imp.plot(x='features', y='importance', kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catclass_risk21 = CatBoostClassifier(\n",
    "    iterations=250,\n",
    "    learning_rate=0.1,\n",
    "    random_strength=0.1,\n",
    "    depth=10,\n",
    "    loss_function='MultiClassOneVsAll',\n",
    "    eval_metric='Accuracy',\n",
    "    leaf_estimation_method='Newton',\n",
    "    thread_count = 4,\n",
    "    class_weights = [2, 1, 2],\n",
    "    ## high, low, med\n",
    "    metric_period=10\n",
    ")\n",
    "modelfit_classification(catclass_risk21, X_train, y_train, X_test, y_test, categorical_features_indices, useTrainCV=True, cv_folds=3, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catclass_risk22 = CatBoostClassifier(\n",
    "    iterations=250,\n",
    "    learning_rate=0.1,\n",
    "    random_strength=0.1,\n",
    "    depth=10,\n",
    "    loss_function='MultiClassOneVsAll',\n",
    "    eval_metric='Accuracy',\n",
    "    leaf_estimation_method='Newton',\n",
    "    thread_count = 4,\n",
    "    class_weights = [1, 1, 1],\n",
    "    ## high, low, med\n",
    "    metric_period=10\n",
    ")\n",
    "modelfit_classification(catclass_risk22, X_train, y_train, X_test, y_test, categorical_features_indices, useTrainCV=True, cv_folds=3, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catclass_risk25 = CatBoostClassifier(\n",
    "    iterations=250,\n",
    "    learning_rate=0.1,\n",
    "    random_strength=0.1,\n",
    "    depth=8,\n",
    "    loss_function='MultiClassOneVsAll',\n",
    "    eval_metric='Accuracy',\n",
    "    leaf_estimation_method='Newton',\n",
    "    thread_count = 4,\n",
    "    class_weights = [3, 1, 1],\n",
    "    ## high, low, med\n",
    "    metric_period=10\n",
    ")\n",
    "modelfit_classification(catclass_risk25, X_train, y_train, X_test, y_test, categorical_features_indices, useTrainCV=True, cv_folds=3, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0: drop model - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(df_final[features], df_final['drops'], test_size=0.1,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_final['drops'])/sum(df_final['drops'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit_classification(alg, X_train, y_train, X_test, y_test, useTrainCV=True, cv_folds=3, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X_train.values, label=y_train.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X_train, y_train, eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_train)\n",
    "    dtrain_predprob = alg.predict_proba(X_train)[:,1]\n",
    "    \n",
    "    #Predict test set:\n",
    "    dtest_predictions = alg.predict(X_test)\n",
    "    dtest_predprob = alg.predict_proba(X_test)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % accuracy_score(y_train, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % roc_auc_score(y_train, dtrain_predprob))\n",
    "    print(classification_report(y_train, dtrain_predictions))\n",
    "    print(confusion_matrix(y_train, dtrain_predictions))\n",
    "    \n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % accuracy_score(y_test.values, dtest_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % roc_auc_score(y_test, dtest_predprob))\n",
    "    print(classification_report(y_test, dtest_predictions))\n",
    "    print(confusion_matrix(y_test, dtest_predictions))\n",
    "                    \n",
    "    feat_imp = pd.DataFrame({'features':features})\n",
    "    feat_imp['importance'] = alg.feature_importances_\n",
    "    feat_imp = feat_imp.sort_values(by = 'importance', ascending=False).head(20)\n",
    "    feat_imp.plot(x='features', y='importance', kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb5 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=50,\n",
    " n_jobs=4,\n",
    " max_depth=8,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " scale_pos_weight=15,\n",
    " max_delta_step=8,\n",
    " reg_alpha=100,\n",
    " seed=27)\n",
    "modelfit_classification(xgb5, X_train, y_train, X_test, y_test, useTrainCV=False, cv_folds=3, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb7 = XGBClassifier(\n",
    " learning_rate =0.2,\n",
    " n_estimators=50,\n",
    " n_jobs=4,\n",
    " max_depth=10,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " scale_pos_weight=12,\n",
    " max_delta_step=8,\n",
    " reg_alpha=100,\n",
    " seed=27)\n",
    "modelfit_classification(xgb7, X_train, y_train, X_test, y_test, useTrainCV=False, cv_folds=3, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost-training",
   "language": "python",
   "name": "xgboost-training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
